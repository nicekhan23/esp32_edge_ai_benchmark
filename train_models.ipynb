{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicekhan23/esp32_edge_ai_benchmark/blob/main/train_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "\n",
        "# ============================================================================\n",
        "# DATA PREPARATION - For CSV with 5000 windows of each waveform\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Loading data from CSV...\")\n",
        "df = pd.read_csv('all_waveforms_combined.csv')  # Your CSV file with 1000 samples per waveform\n",
        "\n",
        "# Extract features and labels\n",
        "print(\"Processing features and labels...\")\n",
        "X = df.drop(['label', 'window_index'], axis=1).values\n",
        "y = df['label'].values\n",
        "\n",
        "# Normalize data (0-4095 to 0-1 range)\n",
        "X = X / 4095.0\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data: 70% train, 15% validation, 15% test\n",
        "print(\"Splitting data...\")\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Create directory structure\n",
        "data_dir = Path(\"esp32_training_data/processed\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save processed data\n",
        "print(\"Saving processed data...\")\n",
        "np.save(data_dir / \"X_train.npy\", X_train)\n",
        "np.save(data_dir / \"X_val.npy\", X_val)\n",
        "np.save(data_dir / \"X_test.npy\", X_test)\n",
        "np.savetxt(data_dir / \"y_train.txt\", y_train, fmt='%d')\n",
        "np.savetxt(data_dir / \"y_val.txt\", y_val, fmt='%d')\n",
        "np.savetxt(data_dir / \"y_test.txt\", y_test, fmt='%d')\n",
        "\n",
        "# Save label encoder classes\n",
        "with open(data_dir / \"label_classes.json\", 'w') as f:\n",
        "    json.dump(label_encoder.classes_.tolist(), f)\n",
        "\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Classes: {label_encoder.classes_}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CNN MODEL (Float32 and INT8)\n",
        "# ============================================================================\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes, quantized=False):\n",
        "    \"\"\"Create a CNN model for waveform classification\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "        tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "        tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train Float32 CNN model\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training CNN Float32 model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model_f32 = create_cnn_model((256, 1), len(label_encoder.classes_))\n",
        "model_f32.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Reshape data for CNN (add channel dimension)\n",
        "X_train_cnn = X_train.reshape(-1, 256, 1)\n",
        "X_val_cnn = X_val.reshape(-1, 256, 1)\n",
        "X_test_cnn = X_test.reshape(-1, 256, 1)\n",
        "\n",
        "history_f32 = model_f32.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate CNN\n",
        "cnn_test_loss, cnn_test_acc = model_f32.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "print(f\"\\nCNN Test Accuracy: {cnn_test_acc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "model_f32.save(\"cnn_float32_model.h5\")\n",
        "print(\"CNN Float32 model saved as 'cnn_float32_model.h5'\")\n",
        "\n",
        "# Convert CNN to INT8\n",
        "print(\"\\nConverting CNN to INT8...\")\n",
        "\n",
        "def representative_dataset_cnn():\n",
        "    for i in range(100):  # Use 100 samples for calibration\n",
        "        yield [X_train_cnn[i:i+1].astype(np.float32)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_f32)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_cnn\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "try:\n",
        "    tflite_model = converter.convert()\n",
        "    with open('cnn_int8_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(\"CNN INT8 model saved as 'cnn_int8_model.tflite'\")\n",
        "\n",
        "    # Get model size\n",
        "    tflite_size = len(tflite_model) / 1024\n",
        "    print(f\"CNN INT8 Model size: {tflite_size:.2f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error converting CNN to INT8: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# MLP MODEL (Multi-Layer Perceptron)\n",
        "# ============================================================================\n",
        "\n",
        "def create_mlp_model(input_shape, num_classes):\n",
        "    \"\"\"Create an MLP model for waveform classification\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train Float32 MLP model\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training MLP Float32 model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model_mlp_f32 = create_mlp_model(256, len(label_encoder.classes_))\n",
        "model_mlp_f32.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_mlp_f32 = model_mlp_f32.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate MLP\n",
        "mlp_test_loss, mlp_test_acc = model_mlp_f32.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nMLP Test Accuracy: {mlp_test_acc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "model_mlp_f32.save(\"mlp_float32_model.h5\")\n",
        "print(\"MLP Float32 model saved as 'mlp_float32_model.h5'\")\n",
        "\n",
        "# Convert MLP to INT8\n",
        "print(\"\\nConverting MLP to INT8...\")\n",
        "\n",
        "def representative_dataset_mlp():\n",
        "    for i in range(100):\n",
        "        yield [X_train[i:i+1].astype(np.float32)]\n",
        "\n",
        "converter_mlp = tf.lite.TFLiteConverter.from_keras_model(model_mlp_f32)\n",
        "converter_mlp.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_mlp.representative_dataset = representative_dataset_mlp\n",
        "converter_mlp.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_mlp.inference_input_type = tf.int8\n",
        "converter_mlp.inference_output_type = tf.int8\n",
        "\n",
        "try:\n",
        "    tflite_model_mlp = converter_mlp.convert()\n",
        "    with open('mlp_int8_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model_mlp)\n",
        "    print(\"MLP INT8 model saved as 'mlp_int8_model.tflite'\")\n",
        "\n",
        "    tflite_size_mlp = len(tflite_model_mlp) / 1024\n",
        "    print(f\"MLP INT8 Model size: {tflite_size_mlp:.2f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error converting MLP to INT8: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# HYBRID MODEL (CNN + MLP)\n",
        "# ============================================================================\n",
        "\n",
        "def create_hybrid_model(input_shape, num_classes):\n",
        "    \"\"\"Create a hybrid CNN+MLP model\"\"\"\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # CNN branch\n",
        "    x = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPooling1D(2)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # MLP branch (direct features)\n",
        "    y = tf.keras.layers.Dense(64, activation='relu')(tf.keras.layers.Flatten()(inputs))\n",
        "    y = tf.keras.layers.BatchNormalization()(y)\n",
        "\n",
        "    # Combine branches\n",
        "    combined = tf.keras.layers.Concatenate()([x, y])\n",
        "    combined = tf.keras.layers.Dense(64, activation='relu')(combined)\n",
        "    combined = tf.keras.layers.Dropout(0.3)(combined)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(combined)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train Float32 Hybrid model\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Hybrid Float32 model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model_hybrid_f32 = create_hybrid_model((256, 1), len(label_encoder.classes_))\n",
        "model_hybrid_f32.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_hybrid_f32 = model_hybrid_f32.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Hybrid\n",
        "hybrid_test_loss, hybrid_test_acc = model_hybrid_f32.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "print(f\"\\nHybrid Test Accuracy: {hybrid_test_acc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "model_hybrid_f32.save(\"hybrid_float32_model.h5\")\n",
        "print(\"Hybrid Float32 model saved as 'hybrid_float32_model.h5'\")\n",
        "\n",
        "# Convert Hybrid to INT8\n",
        "print(\"\\nConverting Hybrid to INT8...\")\n",
        "\n",
        "def representative_dataset_hybrid():\n",
        "    for i in range(100):\n",
        "        yield [X_train_cnn[i:i+1].astype(np.float32)]\n",
        "\n",
        "converter_hybrid = tf.lite.TFLiteConverter.from_keras_model(model_hybrid_f32)\n",
        "converter_hybrid.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_hybrid.representative_dataset = representative_dataset_hybrid\n",
        "converter_hybrid.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_hybrid.inference_input_type = tf.int8\n",
        "converter_hybrid.inference_output_type = tf.int8\n",
        "\n",
        "try:\n",
        "    tflite_model_hybrid = converter_hybrid.convert()\n",
        "    with open('hybrid_int8_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model_hybrid)\n",
        "    print(\"Hybrid INT8 model saved as 'hybrid_int8_model.tflite'\")\n",
        "\n",
        "    tflite_size_hybrid = len(tflite_model_hybrid) / 1024\n",
        "    print(f\"Hybrid INT8 Model size: {tflite_size_hybrid:.2f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error converting Hybrid to INT8: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL COMPARISON AND SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL TRAINING COMPLETED - SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"\\nDataset Information:\")\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
        "print(f\"Classes: {list(label_encoder.classes_)}\")\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"CNN Model Test Accuracy:     {cnn_test_acc:.4f}\")\n",
        "print(f\"MLP Model Test Accuracy:     {mlp_test_acc:.4f}\")\n",
        "print(f\"Hybrid Model Test Accuracy:  {hybrid_test_acc:.4f}\")\n",
        "\n",
        "print(f\"\\nGenerated Models:\")\n",
        "print(\"1. cnn_float32_model.h5\")\n",
        "print(\"2. cnn_int8_model.tflite\")\n",
        "print(\"3. mlp_float32_model.h5\")\n",
        "print(\"4. mlp_int8_model.tflite\")\n",
        "print(\"5. hybrid_float32_model.h5\")\n",
        "print(\"6. hybrid_int8_model.tflite\")\n",
        "\n",
        "print(f\"\\nModel Sizes (INT8):\")\n",
        "print(f\"CNN:     {tflite_size:.2f} KB\")\n",
        "print(f\"MLP:     {tflite_size_mlp:.2f} KB\")\n",
        "print(f\"Hybrid:  {tflite_size_hybrid:.2f} KB\")\n",
        "\n",
        "print(f\"\\nRecommended for ESP32:\")\n",
        "best_model = max(cnn_test_acc, mlp_test_acc, hybrid_test_acc)\n",
        "if best_model == cnn_test_acc:\n",
        "    print(\"✓ Use CNN model - Good accuracy with moderate complexity\")\n",
        "elif best_model == mlp_test_acc:\n",
        "    print(\"✓ Use MLP model - Simple and efficient for ESP32\")\n",
        "else:\n",
        "    print(\"✓ Use Hybrid model - Best accuracy, slightly larger\")\n",
        "\n",
        "# Save training summary\n",
        "summary = {\n",
        "    \"dataset\": {\n",
        "        \"total_samples\": len(X),\n",
        "        \"train_samples\": len(X_train),\n",
        "        \"val_samples\": len(X_val),\n",
        "        \"test_samples\": len(X_test),\n",
        "        \"classes\": label_encoder.classes_.tolist()\n",
        "    },\n",
        "    \"model_performance\": {\n",
        "        \"cnn_accuracy\": float(cnn_test_acc),\n",
        "        \"mlp_accuracy\": float(mlp_test_acc),\n",
        "        \"hybrid_accuracy\": float(hybrid_test_acc)\n",
        "    },\n",
        "    \"model_sizes_kb\": {\n",
        "        \"cnn_int8\": float(tflite_size),\n",
        "        \"mlp_int8\": float(tflite_size_mlp),\n",
        "        \"hybrid_int8\": float(tflite_size_hybrid)\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"training_summary.json\", \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\nTraining summary saved to 'training_summary.json'\")\n",
        "print(\"\\nAll models trained successfully! ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGxH8n_ZKKuO",
        "outputId": "c8e3d03d-3016-4faf-b514-374182f75e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from CSV...\n",
            "Processing features and labels...\n",
            "Splitting data...\n",
            "Saving processed data...\n",
            "\n",
            "Dataset Statistics:\n",
            "Total samples: 20000\n",
            "Training samples: 14000\n",
            "Validation samples: 3000\n",
            "Test samples: 3000\n",
            "Classes: ['SAWTOOTH' 'SINE' 'SQUARE' 'TRIANGLE']\n",
            "\n",
            "==================================================\n",
            "Training CNN Float32 model...\n",
            "==================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 63ms/step - accuracy: 0.9144 - loss: 0.3136 - val_accuracy: 0.2500 - val_loss: 5.4600 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9966 - loss: 0.0171 - val_accuracy: 0.2593 - val_loss: 6.0174 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9980 - loss: 0.0122 - val_accuracy: 0.9800 - val_loss: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.5793 - val_loss: 2.6599 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.9990 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - accuracy: 0.9983 - loss: 0.0069 - val_accuracy: 0.6493 - val_loss: 0.9661 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9991 - loss: 0.0052 - val_accuracy: 0.9977 - val_loss: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 0.9270 - val_loss: 0.1316 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.6817 - val_loss: 0.8971 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.9967 - val_loss: 0.0195 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 65ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.7440 - val_loss: 1.8531 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9982 - loss: 0.0091\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.9982 - loss: 0.0091 - val_accuracy: 0.9990 - val_loss: 0.0068 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.9917 - val_loss: 0.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9983 - val_loss: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.9430 - val_loss: 0.1223 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9847 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9993 - val_loss: 0.0025 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 62ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9320 - val_loss: 0.2137 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9993 - val_loss: 0.0022 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.6503 - val_loss: 4.1424 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 65ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9160 - val_loss: 0.2079 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.9993 - val_loss: 0.0022 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9993 - val_loss: 0.0027 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9500 - val_loss: 0.0963 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.9942 - loss: 0.0178 - val_accuracy: 0.9863 - val_loss: 0.0529 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.0034\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9993 - val_loss: 0.0021 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9990 - val_loss: 0.0026 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0021 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9987 - val_loss: 0.0040 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9993 - val_loss: 0.0020 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9993 - val_loss: 0.0025 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0023 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9993 - val_loss: 0.0025 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 62ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 0.0025 - learning_rate: 1.2500e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9993 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9994 - loss: 0.0027\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.9997 - loss: 8.8125e-04 - val_accuracy: 0.9993 - val_loss: 0.0025 - learning_rate: 6.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 63ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0023 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9990 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
            "Epoch 47: early stopping\n",
            "Restoring model weights from the end of the best epoch: 32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN Test Accuracy: 0.9990\n",
            "CNN Float32 model saved as 'cnn_float32_model.h5'\n",
            "\n",
            "Converting CNN to INT8...\n",
            "Saved artifact at '/tmp/tmpmw83na6e'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 1), dtype=tf.float32, name='keras_tensor_37')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132365092273616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365111228368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637797648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132367554926480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365092271696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637797456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637797264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637798032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637793040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637795536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637795728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637796880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637795920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637797840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637796688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637794384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637794576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637796304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637794768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637793808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637794000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364637793616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN INT8 model saved as 'cnn_int8_model.tflite'\n",
            "CNN INT8 Model size: 57.30 KB\n",
            "\n",
            "==================================================\n",
            "Training MLP Float32 model...\n",
            "==================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6963 - loss: 0.7946 - val_accuracy: 0.8450 - val_loss: 0.5489 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1573 - val_accuracy: 0.9173 - val_loss: 0.1978 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9668 - loss: 0.1087 - val_accuracy: 0.9713 - val_loss: 0.0971 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.0853 - val_accuracy: 0.9987 - val_loss: 0.0342 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9739 - loss: 0.0815 - val_accuracy: 0.9987 - val_loss: 0.0231 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0754 - val_accuracy: 0.9987 - val_loss: 0.0193 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0733 - val_accuracy: 0.9063 - val_loss: 0.2344 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0581 - val_accuracy: 0.9993 - val_loss: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9827 - loss: 0.0533 - val_accuracy: 0.9860 - val_loss: 0.0539 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0395 - val_accuracy: 0.9037 - val_loss: 0.1634 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0437 - val_accuracy: 0.9500 - val_loss: 0.1073 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0400 - val_accuracy: 0.9707 - val_loss: 0.0484 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0468 - val_accuracy: 0.9993 - val_loss: 0.0067 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0336 - val_accuracy: 0.9823 - val_loss: 0.0408 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0348 - val_accuracy: 0.9990 - val_loss: 0.0062 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0260 - val_accuracy: 0.9993 - val_loss: 0.0053 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.9993 - val_loss: 0.0059 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0314 - val_accuracy: 0.9880 - val_loss: 0.0233 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0325 - val_accuracy: 0.9993 - val_loss: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0375 - val_accuracy: 0.9993 - val_loss: 0.0072 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0205 - val_accuracy: 0.9990 - val_loss: 0.0040 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0222 - val_accuracy: 0.9993 - val_loss: 0.0047 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0188 - val_accuracy: 0.9990 - val_loss: 0.0051 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0284 - val_accuracy: 0.9990 - val_loss: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0243 - val_accuracy: 0.9993 - val_loss: 0.0042 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.9993 - val_loss: 0.0041 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0197 - val_accuracy: 0.9750 - val_loss: 0.0555 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0180\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0181 - val_accuracy: 0.9993 - val_loss: 0.0057 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0163 - val_accuracy: 0.9993 - val_loss: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0119 - val_accuracy: 0.9993 - val_loss: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0114 - val_accuracy: 0.9993 - val_loss: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.9993 - val_loss: 0.0028 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9993 - val_loss: 0.0027 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0131 - val_accuracy: 0.9993 - val_loss: 0.0048 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0135 - val_accuracy: 0.9980 - val_loss: 0.0117 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0102 - val_accuracy: 0.9993 - val_loss: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9990 - val_loss: 0.0049 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.9993 - val_loss: 0.0025 - learning_rate: 5.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0119 - val_accuracy: 0.9993 - val_loss: 0.0028 - learning_rate: 5.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9993 - val_loss: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 0.9993 - val_loss: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0117 - val_accuracy: 0.9993 - val_loss: 0.0034 - learning_rate: 5.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0091 - val_accuracy: 0.9993 - val_loss: 0.0034 - learning_rate: 5.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.9993 - val_loss: 0.0034 - learning_rate: 5.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0170\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0169 - val_accuracy: 0.9993 - val_loss: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0080 - val_accuracy: 0.9993 - val_loss: 0.0028 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9993 - val_loss: 0.0034 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0078 - val_accuracy: 0.9993 - val_loss: 0.0035 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0067 - val_accuracy: 0.9993 - val_loss: 0.0036 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0060 - val_accuracy: 0.9993 - val_loss: 0.0033 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 38.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Test Accuracy: 0.9990\n",
            "MLP Float32 model saved as 'mlp_float32_model.h5'\n",
            "\n",
            "Converting MLP to INT8...\n",
            "Saved artifact at '/tmp/tmpjpytxcp0'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256), dtype=tf.float32, name='keras_tensor_50')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132365096293904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096296208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051623760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051622992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096288528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051623568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051622800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051624144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051623376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051621648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051621840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051614928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051622032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051622608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051623952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051620496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051620688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051622416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051620880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051621456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "MLP INT8 model saved as 'mlp_int8_model.tflite'\n",
            "MLP INT8 Model size: 51.57 KB\n",
            "\n",
            "==================================================\n",
            "Training Hybrid Float32 model...\n",
            "==================================================\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.8291 - loss: 0.5168 - val_accuracy: 0.4993 - val_loss: 2.4830 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9958 - loss: 0.0319 - val_accuracy: 0.5127 - val_loss: 3.2253 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9978 - loss: 0.0176 - val_accuracy: 0.7657 - val_loss: 0.5586 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9963 - loss: 0.0174 - val_accuracy: 0.7943 - val_loss: 0.4482 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0081 - val_accuracy: 0.9990 - val_loss: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9979 - loss: 0.0116 - val_accuracy: 0.9807 - val_loss: 0.0729 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9983 - loss: 0.0096 - val_accuracy: 0.9987 - val_loss: 0.0347 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9986 - loss: 0.0075 - val_accuracy: 0.8047 - val_loss: 0.8210 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 0.5087 - val_loss: 1.7806 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 0.9993 - val_loss: 0.0039 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9993 - val_loss: 0.0045 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0047 - val_accuracy: 0.9993 - val_loss: 0.0039 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 0.9993 - val_loss: 0.0030 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.9987 - val_loss: 0.0064 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.8403 - val_loss: 1.1035 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9958 - loss: 0.0114 - val_accuracy: 0.9993 - val_loss: 0.0043 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9990 - loss: 0.0053 - val_accuracy: 0.7433 - val_loss: 1.0236 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9957 - loss: 0.0141 - val_accuracy: 0.9880 - val_loss: 0.0270 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.8007 - val_loss: 0.7103 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9976 - loss: 0.0085\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.9980 - val_loss: 0.0064 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.9993 - val_loss: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9993 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9993 - val_loss: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 0.0034 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9993 - val_loss: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9993 - val_loss: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9993 - val_loss: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9986 - loss: 0.0040 - val_accuracy: 0.9993 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9993 - val_loss: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9993 - val_loss: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9993 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9993 - val_loss: 0.0042 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9987 - val_loss: 0.0045 - learning_rate: 5.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9993 - val_loss: 0.0042 - learning_rate: 5.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9983 - loss: 0.0043\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9993 - val_loss: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0039 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0031 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9988 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0030 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9993 - val_loss: 0.0038 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.9993 - val_loss: 0.0034 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9993 - val_loss: 0.0026 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0022\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0042 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hybrid Test Accuracy: 0.9990\n",
            "Hybrid Float32 model saved as 'hybrid_float32_model.h5'\n",
            "\n",
            "Converting Hybrid to INT8...\n",
            "Saved artifact at '/tmp/tmpkot4kscr'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 1), dtype=tf.float32, name='keras_tensor_60')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132364882858384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096298704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096301008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096296592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096301968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096302160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096294480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096303312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096301584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096296976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096294288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096301200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096300816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096297360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096298320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096300240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096298512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096301776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096293712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096299472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096289488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365096301392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Hybrid INT8 model saved as 'hybrid_int8_model.tflite'\n",
            "Hybrid INT8 Model size: 46.88 KB\n",
            "\n",
            "==================================================\n",
            "MODEL TRAINING COMPLETED - SUMMARY\n",
            "==================================================\n",
            "\n",
            "Dataset Information:\n",
            "Total samples: 20000\n",
            "Number of classes: 4\n",
            "Classes: ['SAWTOOTH', 'SINE', 'SQUARE', 'TRIANGLE']\n",
            "\n",
            "Model Performance:\n",
            "CNN Model Test Accuracy:     0.9990\n",
            "MLP Model Test Accuracy:     0.9990\n",
            "Hybrid Model Test Accuracy:  0.9990\n",
            "\n",
            "Generated Models:\n",
            "1. cnn_float32_model.h5\n",
            "2. cnn_int8_model.tflite\n",
            "3. mlp_float32_model.h5\n",
            "4. mlp_int8_model.tflite\n",
            "5. hybrid_float32_model.h5\n",
            "6. hybrid_int8_model.tflite\n",
            "\n",
            "Model Sizes (INT8):\n",
            "CNN:     57.30 KB\n",
            "MLP:     51.57 KB\n",
            "Hybrid:  46.88 KB\n",
            "\n",
            "Recommended for ESP32:\n",
            "✓ Use CNN model - Good accuracy with moderate complexity\n",
            "\n",
            "Training summary saved to 'training_summary.json'\n",
            "\n",
            "All models trained successfully! ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac61b973",
        "outputId": "5b2fd0ac-67cc-4f59-ac05-1bdcff35769f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Converting Float32 H5 models to Float32 TFLite...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# --- Convert CNN Float32 H5 to TFLite ---\n",
        "print(\"\\nConverting cnn_float32_model.h5 to TFLite...\")\n",
        "model_f32_cnn_h5 = tf.keras.models.load_model('cnn_float32_model.h5')\n",
        "converter_cnn_f32 = tf.lite.TFLiteConverter.from_keras_model(model_f32_cnn_h5)\n",
        "tflite_model_cnn_f32 = converter_cnn_f32.convert()\n",
        "\n",
        "try:\n",
        "    with open('cnn_float32_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model_cnn_f32)\n",
        "    print(\"CNN Float32 TFLite model saved as 'cnn_float32_model.tflite'\")\n",
        "    tflite_size_cnn_f32 = len(tflite_model_cnn_f32) / 1024\n",
        "    print(f\"CNN Float32 TFLite Model size: {tflite_size_cnn_f32:.2f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error converting CNN H5 to Float32 TFLite: {e}\")\n",
        "\n",
        "# --- Convert MLP Float32 H5 to TFLite ---\n",
        "print(\"\\nConverting mlp_float32_model.h5 to TFLite...\")\n",
        "model_f32_mlp_h5 = tf.keras.models.load_model('mlp_float32_model.h5')\n",
        "converter_mlp_f32 = tf.lite.TFLiteConverter.from_keras_model(model_f32_mlp_h5)\n",
        "tflite_model_mlp_f32 = converter_mlp_f32.convert()\n",
        "\n",
        "try:\n",
        "    with open('mlp_float32_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model_mlp_f32)\n",
        "    print(\"MLP Float32 TFLite model saved as 'mlp_float32_model.tflite'\")\n",
        "    tflite_size_mlp_f32 = len(tflite_model_mlp_f32) / 1024\n",
        "    print(f\"MLP Float32 TFLite Model size: {tflite_size_mlp_f32:.2f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error converting MLP H5 to Float32 TFLite: {e}\")\n",
        "\n",
        "# --- Convert Hybrid Float32 H5 to TFLite ---\n",
        "print(\"\\nConverting hybrid_float32_model.h5 to TFLite...\")\n",
        "model_f32_hybrid_h5 = tf.keras.models.load_model('hybrid_float32_model.h5')\n",
        "converter_hybrid_f32 = tf.lite.TFLiteConverter.from_keras_model(model_f32_hybrid_h5)\n",
        "tflite_model_hybrid_f32 = converter_hybrid_f32.convert()\n",
        "\n",
        "try:\n",
        "    with open('hybrid_float32_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model_hybrid_f32)\n",
        "    print(\"Hybrid Float32 TFLite model saved as 'hybrid_float32_model.tflite'\")\n",
        "    tflite_size_hybrid_f32 = len(tflite_model_hybrid_f32) / 1024\n",
        "    print(f\"Hybrid Float32 TFLite Model size: {tflite_size_hybrid_f32:.2f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error converting Hybrid H5 to Float32 TFLite: {e}\")\n",
        "\n",
        "print(\"\\nFloat32 TFLite models generated successfully! ✅\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Converting Float32 H5 models to Float32 TFLite...\n",
            "==================================================\n",
            "\n",
            "Converting cnn_float32_model.h5 to TFLite...\n",
            "Saved artifact at '/tmp/tmpmp9k9kg2'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 1), dtype=tf.float32, name='input_layer_3')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132365061252176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061258512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061257744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061253520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061257936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061259088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061257552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061253328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061253904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061252560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061252944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061253136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061247952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061257360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061246224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061255248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061253712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061252368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061252752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061255824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061254864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365051615888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Float32 TFLite model saved as 'cnn_float32_model.tflite'\n",
            "CNN Float32 TFLite Model size: 165.36 KB\n",
            "\n",
            "Converting mlp_float32_model.h5 to TFLite...\n",
            "Saved artifact at '/tmp/tmpgvklamh_'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256), dtype=tf.float32, name='input_layer_4')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132365055115344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365055115536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866995216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866995600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061258128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132365061251984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866994448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866995024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866994640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866997136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866995984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866995792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866997520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866997328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866996560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866998480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866996752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866996368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866998864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866998288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Float32 TFLite model saved as 'mlp_float32_model.tflite'\n",
            "MLP Float32 TFLite Model size: 172.12 KB\n",
            "\n",
            "Converting hybrid_float32_model.h5 to TFLite...\n",
            "Saved artifact at '/tmp/tmpecnmka5y'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 1), dtype=tf.float32, name='input_layer_5')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132364867000208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866999824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866598096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866597136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866999440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866597904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866597712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866598288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866596368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866596944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866597328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866595984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866596176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866589840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866589648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866594832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866595024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866596752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866595216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866595792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866594064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132364866594640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Hybrid Float32 TFLite model saved as 'hybrid_float32_model.tflite'\n",
            "Hybrid Float32 TFLite Model size: 132.38 KB\n",
            "\n",
            "Float32 TFLite models generated successfully! ✅\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYntzAbxcZVJK10D98jwU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}